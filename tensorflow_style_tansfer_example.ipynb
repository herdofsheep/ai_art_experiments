{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd9f20c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import IPython.display as display\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import PIL\n",
    "\n",
    "mpl.rcParams['figure.figsize'] = (12, 12)\n",
    "mpl.rcParams['axes.grid'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12a36893",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_to_image(tensor):\n",
    "  tensor = tensor*255\n",
    "  tensor = np.array(tensor, dtype=np.uint8)\n",
    "  if np.ndim(tensor)>3:\n",
    "    assert tensor.shape[0] == 1\n",
    "    tensor = tensor[0]\n",
    "  return PIL.Image.fromarray(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "789fdfc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(image, title=None):\n",
    "  if len(image.shape) > 3:\n",
    "    image = tf.squeeze(image, axis=0)\n",
    "\n",
    "  plt.imshow(image)\n",
    "  if title:\n",
    "    plt.title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659562ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_img(path_to_img):\n",
    "  max_dim = 512\n",
    "  img = tf.io.read_file(path_to_img)\n",
    "  img = tf.image.decode_image(img, channels=3, expand_animations=False)\n",
    "  img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "\n",
    "  shape = tf.cast(tf.shape(img)[:2], tf.float32)\n",
    "  long_dim = tf.reduce_max(shape)\n",
    "  scale = max_dim / long_dim\n",
    "\n",
    "  new_shape = tf.cast(shape * scale, tf.int32)\n",
    "\n",
    "  img = tf.image.resize(img, new_shape)\n",
    "  img = img[tf.newaxis, :]\n",
    "  return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "09c54486",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_img_fixed(path_to_img, size=256):\n",
    "  img = tf.io.read_file(path_to_img)\n",
    "  img = tf.image.decode_image(img, channels=3, expand_animations=False)\n",
    "  img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "  img = tf.image.resize(img, [size, size])\n",
    "  img = img[tf.newaxis, :]\n",
    "  return img\n",
    "\n",
    "\n",
    "def get_style_embeddings(style_paths):\n",
    "    embeddings = []\n",
    "    for path in style_paths:\n",
    "        try:\n",
    "            img = load_img_fixed(path) # Ensure this returns a float32 tensor [1, H, W, 3]\n",
    "            embeddings.append(img)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading style image {path}: {e}\")\n",
    "            continue\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2b83fc3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "content_paths = [f\"data/content/{f}\" for f in os.listdir(\"data/content\")]\n",
    "style_paths = [f\"data/style/{f}\" for f in os.listdir(\"data/style\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c11c2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading style image data/style/.DS_Store: {{function_node __wrapped__ReadFile_device_/job:localhost/replica:0/task:0/device:CPU:0}} data/style/.DS_Store; No such file or directory [Op:ReadFile]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-01 15:49:53.750312: W tensorflow/core/framework/op_kernel.cc:1855] OP_REQUIRES failed at whole_file_read_ops.cc:117 : NOT_FOUND: data/style/.DS_Store; No such file or directory\n",
      "2026-01-01 15:49:53.750375: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: NOT_FOUND: data/style/.DS_Store; No such file or directory\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_hub as hub\n",
    "\n",
    "num = 0\n",
    "\n",
    "for style_path in style_paths:\n",
    "    hub_model = hub.load('models/arbitrary-image-stylization-v1-tensorflow1-256-v2')\n",
    "    style_img = load_img(style_path)\n",
    "    content_img = load_img(content_paths[0])\n",
    "    stylized_image = hub_model(tf.constant(content_img), tf.constant(style_img))[0]\n",
    "    output_image = tensor_to_image(stylized_image)\n",
    "    output_image.save(f\"all_styles_grid2/{num}.png\")\n",
    "    num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bcb69b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RANDOM STYLE\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "animation_frames = [f\"data/animation/{f}\" for f in os.listdir(\"data/animation\")]\n",
    "style_paths = [f\"data/style/{f}\" for f in os.listdir(\"data/style\")]\n",
    "\n",
    "num = 0\n",
    "\n",
    "for frame in animation_frames:\n",
    "    hub_model = hub.load('models/arbitrary-image-stylization-v1-tensorflow1-256-v2')\n",
    "    random_style_int = np.random.randint(0, len(style_paths))\n",
    "    try:\n",
    "        style_img = load_img(style_paths[random_style_int])\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading style image {style_path}: {e}\")\n",
    "        continue\n",
    "    content_img = load_img(frame)\n",
    "    stylized_image = hub_model(tf.constant(content_img), tf.constant(style_img))[0]\n",
    "    output_image = tensor_to_image(stylized_image)\n",
    "    output_image.save(f\"outputs/cube_animation_1/{num}.png\")\n",
    "    num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "71e86dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AVERAGE STYLE\n",
    "import glob\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "animation_frames = sorted(glob.glob('data/animation/*.png'))\n",
    "style_paths = [f\"data/style2/{f}\" for f in os.listdir(\"data/style2\")]\n",
    "\n",
    "style_embeddings = get_style_embeddings(style_paths)\n",
    "avg_style = tf.reduce_mean(tf.concat(style_embeddings, axis=0), axis=0, keepdims=True)\n",
    "\n",
    "num = 0\n",
    "\n",
    "for frame in animation_frames:\n",
    "    hub_model = hub.load('models/arbitrary-image-stylization-v1-tensorflow1-256-v2')\n",
    "    random_style_int = np.random.randint(0, len(style_paths))\n",
    "    stylized_image = hub_model(tf.constant(content_img), tf.constant(avg_style))[0]\n",
    "    output_image = tensor_to_image(stylized_image)\n",
    "    output_image.save(f\"outputs/cube_animation_2/{num}.png\")\n",
    "    num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed972a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRANSITIONING STYLES\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load model once\n",
    "hub_model = hub.load('https://tfhub.dev/google/magenta/arbitrary-image-stylization-v1-256/2')\n",
    "\n",
    "def get_style_vector(path):\n",
    "    # This model treats the style image input as the source for the bottleneck\n",
    "    return load_img(path)\n",
    "\n",
    "# Pre-load your style images\n",
    "style_tensors = [get_style_vector(p) for p in style_paths]\n",
    "num_frames = len(animation_frames)\n",
    "num_styles = len(style_tensors)\n",
    "\n",
    "for i, frame_path in enumerate(animation_frames):\n",
    "    # Determine which two styles we are between\n",
    "    # This maps the current frame index to a float position in the style list\n",
    "    style_idx_float = (i / (num_frames - 1)) * (num_styles - 1)\n",
    "    idx1 = int(np.floor(style_idx_float))\n",
    "    idx2 = int(np.ceil(style_idx_float))\n",
    "    \n",
    "    # Calculate the blend weight (0.0 to 1.0)\n",
    "    fraction = style_idx_float - idx1\n",
    "    \n",
    "    # Interpolate between the two style images\n",
    "    # This creates a 'morphed' style image for this specific frame\n",
    "    interpolated_style = (1 - fraction) * style_tensors[idx1] + fraction * style_tensors[idx2]\n",
    "    \n",
    "    # Run Stylization\n",
    "    content_img = load_img(frame_path)\n",
    "    stylized_image = hub_model(tf.constant(content_img), tf.constant(interpolated_style))[0]\n",
    "    \n",
    "    output_image = tensor_to_image(stylized_image)\n",
    "    output_image.save(f\"outputs/cube_animation_3/{i:04d}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0ace0374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to outputs/4.png\n"
     ]
    }
   ],
   "source": [
    "#SINGLE STYLE\n",
    "\n",
    "content_path = \"data/content/grid1.jpg\"\n",
    "style_path = \"data/style/pomelo.jpeg\"\n",
    "\n",
    "content_img = load_img(content_path)\n",
    "style_img = load_img(style_path)\n",
    "\n",
    "# Find the next available number\n",
    "import re\n",
    "existing = [f for f in os.listdir(\"outputs\") if re.match(r'^\\d+\\.png$', f)]\n",
    "if existing:\n",
    "    nums = [int(re.match(r'^(\\d+)\\.png$', f).group(1)) for f in existing]\n",
    "    num = max(nums) + 1\n",
    "else:\n",
    "    num = 1\n",
    "\n",
    "stylized_image = hub_model(tf.constant(content_img), tf.constant(style_img))[0]\n",
    "\n",
    "# Save the stylized image\n",
    "output_image = tensor_to_image(stylized_image)\n",
    "output_image.save(f\"outputs/{num}.png\")\n",
    "print(f\"Saved to outputs/{num}.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
