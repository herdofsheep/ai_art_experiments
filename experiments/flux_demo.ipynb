{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8f42c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/megan/Documents/art/jan_collab/style_transfer/.venv/lib/python3.12/site-packages/keras/src/export/tf2onnx_lib.py:8: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(np, \"object\"):\n",
      "/Users/megan/Documents/art/jan_collab/style_transfer/.venv/lib/python3.12/site-packages/torch/amp/autocast_mode.py:270: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Keep huggingface dependencies in this repo\n",
    "import os\n",
    "os.environ['HF_HOME'] = '../models/huggingface'\n",
    "\n",
    "import huggingface_hub\n",
    "if not hasattr(huggingface_hub, 'cached_download'):\n",
    "    from huggingface_hub import hf_hub_download\n",
    "    huggingface_hub.cached_download = hf_hub_download\n",
    "\n",
    "import torch\n",
    "from diffusers import FluxPipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613ad9bc",
   "metadata": {},
   "source": [
    "### log in to huggingface with:\n",
    "\n",
    "1. make an account on huggingface.org\n",
    "2. huggingface-cli login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90884bd6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'FluxPipeline' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      4\u001b[39m model_id = \u001b[33m\"\u001b[39m\u001b[33mblack-forest-labs/FLUX.1-schnell\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;66;03m# This is like 60 GB\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# model_id = \"black-forest-labs/FLUX.2-dev\" # this is like 125GB\u001b[39;00m\n\u001b[32m      6\u001b[39m \n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Load the pipeline for Mac (MPS) or PC (CUDA)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m pipe = \u001b[43mFluxPipeline\u001b[49m.from_pretrained(model_id, torch_dtype=torch.bfloat16)\n\u001b[32m      9\u001b[39m pipe.enable_model_cpu_offload() \n",
      "\u001b[31mNameError\u001b[39m: name 'FluxPipeline' is not defined"
     ]
    }
   ],
   "source": [
    "# Use \"black-forest-labs/FLUX.1-schnell\" for speed (4 steps)\n",
    "# Use \"black-forest-labs/FLUX.1-dev\" for higher quality (20-30 steps)\n",
    "\n",
    "model_id = \"black-forest-labs/FLUX.1-schnell\" # This is like 60 GB\n",
    "# model_id = \"black-forest-labs/FLUX.2-dev\" # this is like 125GB\n",
    "\n",
    "# Load the pipeline for Mac (MPS) or PC (CUDA)\n",
    "pipe = FluxPipeline.from_pretrained(model_id, torch_dtype=torch.bfloat16)\n",
    "pipe.enable_model_cpu_offload() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c24483",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import DiffusionPipeline\n",
    "\n",
    "# switch to \"mps\" for apple devices\n",
    "pipe = DiffusionPipeline.from_pretrained(\"black-forest-labs/FLUX.2-dev\", dtype=torch.bfloat16, device_map=\"cuda\")\n",
    "\n",
    "prompt = \"Turn this cat into a dog\"\n",
    "input_image = load_image(\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/cat.png\")\n",
    "\n",
    "image = pipe(image=input_image, prompt=prompt).images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5ab617",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"A cinematic animation frame in the style of van gogh, vibrant oil paint\"\n",
    "\n",
    "# For Schnell, use 4 steps. For Dev, use 20-30.\n",
    "image = pipe(\n",
    "    prompt,\n",
    "    guidance_scale=0.0, # Schnell needs 0.0\n",
    "    num_inference_steps=4, \n",
    "    max_sequence_length=256\n",
    ").images[0]\n",
    "\n",
    "image.save(\"../outputs/output_frame.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
